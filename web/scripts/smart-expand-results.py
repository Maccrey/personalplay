#!/usr/bin/env python3
"""
Smart template-based result expansion
Creates unique, contextually relevant content based on keywords in existing descriptions
"""

import json
import sys
from pathlib import Path
import re

sys.stdout.reconfigure(line_buffering=True)

# Keyword-based content templates for different aspects
PERSONALITY_KEYWORDS = {
    'ì—´ì •': {
        'chars': ['ì ê·¹ì ì´ê³  ì—ë„ˆì§€ ë„˜ì¹˜ëŠ” ì„±í–¥', 'ëª©í‘œë¥¼ í–¥í•´ ì—´ì •ì ìœ¼ë¡œ ë‚˜ì•„ê°€ëŠ” ìŠ¤íƒ€ì¼', 'ì£¼ë³€ ì‚¬ëŒë“¤ì—ê²Œ ê¸ì •ì ì¸ ì˜í–¥ì„ ì¤Œ'],
        'strengths': ['ë†’ì€ ë™ê¸°ë¶€ì—¬ì™€ ì¶”ì§„ë ¥', 'ì–´ë ¤ì›€ ì•ì—ì„œë„ í¬ê¸°í•˜ì§€ ì•ŠëŠ” ëˆê¸°', 'ì£¼ë³€ì— í™œë ¥ì„ ë¶ˆì–´ë„£ëŠ” ëŠ¥ë ¥'],
        'weaknesses': ['ë•Œë¡œëŠ” ê³¼ë„í•œ ì—´ì •ìœ¼ë¡œ ë²ˆì•„ì›ƒ ìœ„í—˜', 'ì„¬ì„¸í•œ ë¶€ë¶„ì„ ë†“ì¹  ìˆ˜ ìˆìŒ'],
        'advice': 'ì—´ì •ì„ ìœ ì§€í•˜ë©´ì„œë„ ì ì ˆí•œ íœ´ì‹ì„ ì·¨í•˜ì„¸ìš”. ì¥ê¸°ì ì¸ ê´€ì ì—ì„œ ê· í˜•ì„ ë§ì¶”ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.'
    },
    'ì°¨ë¶„': {
        'chars': ['ì¹¨ì°©í•˜ê³  ì•ˆì •ì ì¸ ì„±í–¥', 'ìƒí™©ì„ ê°ê´€ì ìœ¼ë¡œ íŒë‹¨í•˜ëŠ” ëŠ¥ë ¥', 'ê°ì • ì¡°ì ˆì´ ë›°ì–´ë‚¨'],
        'strengths': ['ëƒ‰ì •í•œ íŒë‹¨ë ¥ê³¼ ë¶„ì„ ëŠ¥ë ¥', 'ìŠ¤íŠ¸ë ˆìŠ¤ ìƒí™©ì—ì„œë„ í‰ì •ì‹¬ ìœ ì§€', 'ì‹ ë¢°ê°ì„ ì£¼ëŠ” íƒœë„'],
        'weaknesses': ['ë•Œë¡œëŠ” ë„ˆë¬´ ì‹ ì¤‘í•´ ê¸°íšŒë¥¼ ë†“ì¹  ìˆ˜ ìˆìŒ', 'ê°ì • í‘œí˜„ì´ ë¶€ì¡±í•´ ë³´ì¼ ìˆ˜ ìˆìŒ'],
        'advice': 'ì•ˆì •ì„±ë„ ì¤‘ìš”í•˜ì§€ë§Œ, ë•Œë¡œëŠ” ê³¼ê°í•œ ë„ì „ë„ í•„ìš”í•©ë‹ˆë‹¤. ìì‹ ì˜ ê°ì •ì„ ì ì ˆíˆ í‘œí˜„í•˜ëŠ” ì—°ìŠµì„ í•´ë³´ì„¸ìš”.'
    },
    'ì†Œí†µ': {
        'chars': ['íƒ€ì¸ê³¼ì˜ êµë¥˜ë¥¼ ì¦ê¸°ëŠ” ì„±í–¥', 'ê³µê° ëŠ¥ë ¥ì´ ë›°ì–´ë‚¨', 'ëŒ€í™”ë¥¼ í†µí•´ ê´€ê³„ë¥¼ ë°œì „ì‹œí‚´'],
        'strengths': ['ë›°ì–´ë‚œ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ëŠ¥ë ¥', 'ë‹¤ì–‘í•œ ì‚¬ëŒë“¤ê³¼ ì˜ ì–´ìš¸ë¦¼', 'íŒ€ì›Œí¬ì™€ í˜‘ë ¥ ëŠ¥ë ¥'],
        'weaknesses': ['í˜¼ìë§Œì˜ ì‹œê°„ì´ ë¶€ì¡±í•  ìˆ˜ ìˆìŒ', 'íƒ€ì¸ì˜ ì˜ê²¬ì— ê³¼ë„í•˜ê²Œ ì˜í–¥ë°›ì„ ìˆ˜ ìˆìŒ'],
        'advice': 'ì¢‹ì€ ì†Œí†µ ëŠ¥ë ¥ì„ ìœ ì§€í•˜ë©´ì„œë„, ìì‹ ë§Œì˜ ì˜ê²¬ê³¼ ê°€ì¹˜ê´€ì„ í™•ë¦½í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.'
    },
    'ë…ë¦½': {
        'chars': ['ìê¸°ì£¼ë„ì ì´ê³  ë…ë¦½ì ì¸ ì„±í–¥', 'ìŠ¤ìŠ¤ë¡œ ê²°ì •í•˜ê³  ì±…ì„ì§€ëŠ” íƒœë„', 'ìì‹ ë§Œì˜ ê¸¸ì„ ê°œì²™í•¨'],
        'strengths': ['ê°•í•œ ìë¦½ì‹¬ê³¼ ì£¼ì²´ì„±', 'ì°½ì˜ì ì¸ ë¬¸ì œ í•´ê²° ëŠ¥ë ¥', 'ìê¸° ê´€ë¦¬ ëŠ¥ë ¥'],
        'weaknesses': ['ë•Œë¡œëŠ” ë„ì›€ì„ ìš”ì²­í•˜ê¸° ì–´ë ¤ì›Œí•¨', 'ê³ ì§‘ì´ ì„¸ë‹¤ëŠ” í‰ê°€ë¥¼ ë°›ì„ ìˆ˜ ìˆìŒ'],
        'advice': 'ë…ë¦½ì„±ì„ ìœ ì§€í•˜ë©´ì„œë„, í•„ìš”í•  ë•ŒëŠ” íƒ€ì¸ì˜ ë„ì›€ì„ ë°›ì•„ë“¤ì´ëŠ” ìœ ì—°í•¨ì„ ê°€ì§€ì„¸ìš”.'
    },
    'ì°½ì˜': {
        'chars': ['ë…ì°½ì ì´ê³  í˜ì‹ ì ì¸ ì‚¬ê³ ë°©ì‹', 'ìƒˆë¡œìš´ ì•„ì´ë””ì–´ë¥¼ ì˜ ë– ì˜¬ë¦¼', 'í‹€ì— ë°•íˆì§€ ì•Šì€ ì ‘ê·¼'],
        'strengths': ['í’ë¶€í•œ ìƒìƒë ¥ê³¼ ì°½ì˜ì„±', 'ë¬¸ì œë¥¼ ë‹¤ì–‘í•œ ê°ë„ì—ì„œ ë°”ë¼ë´„', 'í˜ì‹ ì ì¸ í•´ê²°ì±… ì œì‹œ'],
        'weaknesses': ['í˜„ì‹¤ì ì¸ ì œì•½ì„ ê°„ê³¼í•  ìˆ˜ ìˆìŒ', 'ì²´ê³„ì ì¸ ì‹¤í–‰ë ¥ì´ ë¶€ì¡±í•  ìˆ˜ ìˆìŒ'],
        'advice': 'ì°½ì˜ì„±ì„ ë°œíœ˜í•˜ë˜, ì‹¤í˜„ ê°€ëŠ¥ì„±ë„ í•¨ê»˜ ê³ ë ¤í•˜ì„¸ìš”. ì•„ì´ë””ì–´ë¥¼ êµ¬ì²´í™”í•˜ëŠ” ëŠ¥ë ¥ì„ í‚¤ìš°ë©´ ë”ìš± ë¹›ë‚  ê²ƒì…ë‹ˆë‹¤.'
    },
    'ê³„íš': {
        'chars': ['ì²´ê³„ì ì´ê³  ì¡°ì§ì ì¸ ì„±í–¥', 'ëª©í‘œ ë‹¬ì„±ì„ ìœ„í•œ ë¡œë“œë§µì„ ì˜ ìˆ˜ë¦½í•¨', 'ì² ì €í•œ ì¤€ë¹„ì„±'],
        'strengths': ['ë›°ì–´ë‚œ ê³„íš ìˆ˜ë¦½ ëŠ¥ë ¥', 'ì‹œê°„ ê´€ë¦¬ì™€ ìš°ì„ ìˆœìœ„ ì„¤ì •ì— ëŠ¥í•¨', 'ëª©í‘œ ë‹¬ì„±ë¥ ì´ ë†’ìŒ'],
        'weaknesses': ['ì˜ˆìƒì¹˜ ëª»í•œ ë³€ìˆ˜ì— ë‹¹í™©í•  ìˆ˜ ìˆìŒ', 'ì™„ë²½ì£¼ì˜ë¡œ ìŠ¤íŠ¸ë ˆìŠ¤ ë°›ì„ ìˆ˜ ìˆìŒ'],
        'advice': 'ê³„íšì„±ì„ ìœ ì§€í•˜ë˜, ë³€í™”ì— ëŒ€ì‘í•˜ëŠ” ìœ ì—°ì„±ë„ í•¨ê»˜ í‚¤ì›Œë³´ì„¸ìš”. ë•Œë¡œëŠ” ì¦‰í¥ì ì¸ ìˆœê°„ë„ ì¦ê¸°ëŠ” ì—¬ìœ ë¥¼ ê°€ì§€ì„¸ìš”.'
    },
}

def extract_keywords(text):
    """Extract relevant keywords from description"""
    keywords = []
    for keyword in PERSONALITY_KEYWORDS.keys():
        if keyword in text:
            keywords.append(keyword)
    return keywords

def generate_expanded_content(title, desc, test_title):
    """Generate contextually appropriate expanded content"""

    # Extract keywords
    combined_text = f"{title} {desc} {test_title}"
    keywords = extract_keywords(combined_text)

    # If no keywords match, use generic approach
    if not keywords:
        # Use title/desc length and characters to generate variety
        seed = len(title) + len(desc)
        variation = seed % 3

        characteristics = [
            f"{desc}",
            ["ì´ ìœ í˜•ì€ ë…íŠ¹í•œ ê°œì„±ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.", "ìì‹ ë§Œì˜ ìŠ¤íƒ€ì¼ì„ ì¶”êµ¬í•©ë‹ˆë‹¤.", "ê· í˜•ì¡íŒ ì‚¬ê³ ë°©ì‹ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤."][variation],
            ["ìƒí™©ì— ë§ê²Œ ìœ ì—°í•˜ê²Œ ëŒ€ì²˜í•©ë‹ˆë‹¤.", "ì¼ê´€ì„± ìˆëŠ” í–‰ë™ íŒ¨í„´ì„ ë³´ì…ë‹ˆë‹¤.", "ìƒˆë¡œìš´ í™˜ê²½ì—ë„ ì˜ ì ì‘í•©ë‹ˆë‹¤."][variation],
            ["íƒ€ì¸ì„ ë°°ë ¤í•˜ëŠ” ë§ˆìŒì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.", "ìì‹ ì˜ ê°€ì¹˜ê´€ì´ ëª…í™•í•©ë‹ˆë‹¤.", "ëŠì„ì—†ì´ ì„±ì¥í•˜ë ¤ ë…¸ë ¥í•©ë‹ˆë‹¤."][variation]
        ]

        strengths = [
            ["ê¸ì •ì ì¸ ë§ˆì¸ë“œë¡œ ì–´ë ¤ì›€ì„ ê·¹ë³µí•©ë‹ˆë‹¤.", "ì‹¤ìš©ì ì¸ ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.", "ëª©í‘œ ì§€í–¥ì ì¸ íƒœë„ë¥¼ ë³´ì…ë‹ˆë‹¤."][variation],
            ["íƒ€ì¸ê³¼ì˜ ê´€ê³„ì—ì„œ ì‹ ë¢°ë¥¼ ì–»ìŠµë‹ˆë‹¤.", "ìƒˆë¡œìš´ ê²½í—˜ì„ ì¦ê¹ë‹ˆë‹¤.", "ì±…ì„ê°ì´ ê°•í•©ë‹ˆë‹¤."][variation],
            ["ìê¸° ê³„ë°œì— ê´€ì‹¬ì´ ë§ìŠµë‹ˆë‹¤.", "ê· í˜•ì¡íŒ íŒë‹¨ë ¥ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.", "ì§„ì •ì„± ìˆëŠ” íƒœë„ë¥¼ ë³´ì…ë‹ˆë‹¤."][variation]
        ]

        weaknesses = [
            ["ë•Œë¡œëŠ” ìì‹ ì˜ ê°ì •ì„ í‘œí˜„í•˜ëŠ” ë° ì–´ë ¤ì›€ì„ ê²ªì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.", "ìŠ¤íŠ¸ë ˆìŠ¤ ê´€ë¦¬ê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.", "íƒ€ì¸ì˜ ì‹œì„ ì„ ì˜ì‹í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."][variation],
            ["ì™„ë²½ì„ ì¶”êµ¬í•˜ë‹¤ ì§€ì¹  ìˆ˜ ìˆìŠµë‹ˆë‹¤.", "ê²°ì •ì„ ë‚´ë¦¬ëŠ” ë° ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.", "ìì‹ ì—ê²Œ ë„ˆë¬´ ì—„ê²©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."][variation],
            ["ë³€í™”ë¥¼ ë°›ì•„ë“¤ì´ê¸° ì–´ë ¤ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.", "ìš°ì„ ìˆœìœ„ ì„¤ì •ì— ê³ ë¯¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.", "í˜¼ì ëª¨ë“  ê²ƒì„ í•´ê²°í•˜ë ¤ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."][variation]
        ]

        advice = [
            "ìì‹ ì˜ ì¥ì ì„ ë”ìš± ë°œì „ì‹œí‚¤ê³ , ì•½ì ì€ ë³´ì™„í•´ë‚˜ê°€ì„¸ìš”. ê· í˜•ì¡íŒ ì„±ì¥ì´ ì¤‘ìš”í•©ë‹ˆë‹¤.",
            "ìì‹ ë§Œì˜ ì†ë„ë¡œ ë‚˜ì•„ê°€ë˜, ë•Œë¡œëŠ” ì£¼ë³€ì˜ ì¡°ì–¸ì—ë„ ê·€ ê¸°ìš¸ì´ì„¸ìš”. í•¨ê»˜ ì„±ì¥í•˜ëŠ” ê²ƒë„ ê°€ì¹˜ìˆìŠµë‹ˆë‹¤.",
            "í˜„ì¬ì˜ ëª¨ìŠµë„ ì¶©ë¶„íˆ ì¢‹ì§€ë§Œ, ë” ë‚˜ì€ ìì‹ ì„ ìœ„í•´ ë…¸ë ¥í•˜ëŠ” ê³¼ì •ì„ ì¦ê¸°ì„¸ìš”. ì‘ì€ ë³€í™”ë“¤ì´ ëª¨ì—¬ í° ì„±ì¥ì„ ë§Œë“­ë‹ˆë‹¤."
        ][variation]

    else:
        # Use keyword-based templates
        primary_keyword = keywords[0]
        template = PERSONALITY_KEYWORDS[primary_keyword]

        characteristics = [
            desc,
            template['chars'][0],
            template['chars'][1] if len(template['chars']) > 1 else "ìì‹ ë§Œì˜ ê°•ì ì„ ì˜ í™œìš©í•©ë‹ˆë‹¤.",
            template['chars'][2] if len(template['chars']) > 2 else "ì§€ì†ì ìœ¼ë¡œ ë°œì „í•´ë‚˜ê°€ëŠ” ëª¨ìŠµì„ ë³´ì…ë‹ˆë‹¤."
        ]

        strengths = template['strengths'][:3]
        weaknesses = template['weaknesses'][:3] if len(template['weaknesses']) >= 3 else template['weaknesses'] + ["ìê¸° ì¸ì‹ì„ ë†’ì´ë©´ ê°œì„  ê°€ëŠ¥í•©ë‹ˆë‹¤."]
        advice = template['advice']

    # Create summary (first 50 chars of desc)
    summary = desc if len(desc) <= 50 else desc[:47] + "..."

    return {
        "title": title,
        "summary": summary,
        "description": desc,
        "characteristics": characteristics,
        "strengths": strengths,
        "weaknesses": weaknesses,
        "advice": advice
    }

ko_path = Path(__file__).parent.parent / 'locales' / 'ko.json'

print("Loading Korean locale file...", flush=True)
with open(ko_path, encoding='utf-8') as f:
    ko = json.load(f)

# Count total results
total_results = 0
for test_num in range(1, 61):
    test_id = str(test_num)
    if test_id in ko['tests']:
        total_results += len(ko['tests'][test_id]['results'])

print(f"Total results to expand: {total_results}", flush=True)
print("=" * 60, flush=True)

count = 0
for test_num in range(1, 61):
    test_id = str(test_num)

    if test_id not in ko['tests']:
        continue

    test_ko = ko['tests'][test_id]
    test_title = test_ko['title']

    print(f"\nğŸ“ Test {test_id}/60: {test_title}", flush=True)
    print("-" * 60, flush=True)

    for result_key in test_ko['results'].keys():
        result_ko = test_ko['results'][result_key]
        count += 1

        # Skip if already expanded
        if 'characteristics' in result_ko:
            print(f"  âœ“ [{count}/{total_results}] Result {result_key}: {result_ko['title']} (already expanded)", flush=True)
            continue

        print(f"  ğŸ”¨ [{count}/{total_results}] Result {result_key}: {result_ko['title']}", flush=True)

        # Get simple desc
        simple_desc = result_ko.get('desc', result_ko.get('summary', ''))

        # Expand using smart templates
        expanded = generate_expanded_content(
            result_ko['title'],
            simple_desc,
            test_title
        )

        # Update result
        ko['tests'][test_id]['results'][result_key] = expanded

        print(f"     âœ… Expanded", flush=True)

    # Save checkpoint every 10 tests
    if test_num % 10 == 0:
        print(f"\nğŸ’¾ Checkpoint: Saving at Test {test_num}...", flush=True)
        with open(ko_path, 'w', encoding='utf-8') as f:
            json.dump(ko, f, ensure_ascii=False, indent=2)

print("\n" + "=" * 60, flush=True)
print("ğŸ’¾ Final save...", flush=True)
with open(ko_path, 'w', encoding='utf-8') as f:
    json.dump(ko, f, ensure_ascii=False, indent=2)

print(f"\nâœ¨ All {count} results expanded successfully!", flush=True)
print("\nNext step: Run translation script to generate EN/JA versions", flush=True)
